{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning\n",
        "### TP3: Principal Component Analysis"
      ],
      "metadata": {
        "id": "3VZLvaN2B2bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1 Import the Necessary Modules"
      ],
      "metadata": {
        "id": "nAyUeYDACOAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNnb7aY5B06H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Pandas`: This library provides data structures for efficiently storing and manipulating large datasets. It is often used to read in and work with CSV files, as well as to clean and transform data.\n",
        "\n",
        "`NumPy`: This library provides support for large, multi-dimensional arrays and matrices. It is often used in scientific computing and data analysis.\n",
        "\n",
        "`scikit-learn`: This library provides tools for machine learning and data analysis. The specific submodule, \"decomposition,\" provides tools for performing principal component analysis (PCA), a technique used for reducing the dimensionality of large datasets.\n",
        "\n",
        "`Matplotlib`: This library provides tools for creating visualizations in Python, including line charts, scatterplots, and histograms."
      ],
      "metadata": {
        "id": "j6wLajy2CAg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Obtain the Dataset"
      ],
      "metadata": {
        "id": "dsJRWIDCCYaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "df = pd.read_csv(url, names=['sepal length', 'sepal width' , 'petal length', 'petal width', 'target'])"
      ],
      "metadata": {
        "id": "TeJPSd1UCegt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"`: This line defines a variable `url` as the location of the CSV file to be read. In this case, the CSV file is hosted at a URL provided by the UCI Machine Learning Repository and contains data on the iris flower.\n",
        "\n",
        "`df = pd.read_csv(url, names=['sepal length', 'sepal width' , 'petal length', 'petal width', 'target'])`: This line reads the CSV file at the url location and stores it in a pandas DataFrame named `df`. The names argument specifies the column names for the DataFrame. In this case, the CSV file does not contain column names, so we supply them explicitly. The column names are `'sepal length'`, `'sepal width'`, `'petal length'`, `'petal width'`, and `'target'`, corresponding to the measurements of the iris flowers and their species."
      ],
      "metadata": {
        "id": "CuPfWzlYgSbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Preview Your Data"
      ],
      "metadata": {
        "id": "SA-LxPx4CfLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "4k7P7fkXCu6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Center and Perform Scaling on the Data"
      ],
      "metadata": {
        "id": "bwwGuFbICvpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
        "x = df.loc[:, features].values\n",
        "y = df.loc[:, ['target']].values\n",
        "x = StandardScaler().fit_transform(x)"
      ],
      "metadata": {
        "id": "uf0GMPOgC2MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet standardizes the features of the iris dataset by scaling them to have a mean of 0 and a standard deviation of 1. Here is an explanation of each line of code:\n",
        "\n",
        "`from sklearn.preprocessing import StandardScaler`: This line imports the StandardScaler class from the preprocessing module of the scikit-learn library. This class is used to standardize features by removing the mean and scaling to unit variance.\n",
        "\n",
        "`features = ['sepal length', 'sepal width', 'petal length', 'petal width']`: This line defines a list of feature names that will be standardized. These features correspond to the measurements of the iris flowers.\n",
        "\n",
        "`x = df.loc[:, features].values`: This line selects the columns of the DataFrame df that correspond to the feature names in the features list, and stores them in the variable `x`. The `.loc` accessor is used to select columns by label, and the `.values` property is used to return a `NumPy` array.\n",
        "\n",
        "`y = df.loc[:, ['target']].values`: This line selects the column of the DataFrame df that corresponds to the target variable, which in this case is the species of the iris flower. The column is stored in the variable `y` as a `NumPy` array.\n",
        "\n",
        "`x = StandardScaler().fit_transform(x)`: This line standardizes the features in `x` using the `StandardScaler` class. First, a new `StandardScaler` object is created using the default parameters. Then, the `fit_transform()` method is called on this object, which fits the scaler to the data in `x` and returns the standardized data. The standardized data is stored back in the `x` variable.\n",
        "\n",
        "Overall, this code standardizes the features of the iris dataset in preparation for further analysis and modeling. Standardizing features can help to improve the performance of certain machine learning algorithms, particularly those that rely on distance measures or assume normally distributed data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nfU8zt_6hRGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5:  Perform PCA"
      ],
      "metadata": {
        "id": "lxBfUbLyC2t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=4)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2', 'PC3', 'PC4'])\n",
        "print(principalDataframe)"
      ],
      "metadata": {
        "id": "J2589cAiDDn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet performs Principal Component Analysis (PCA) on the standardized features of the iris dataset and creates a new DataFrame containing the principal components. Here is an explanation of each line of code:\n",
        "\n",
        "`pca = PCA(n_components=4)`: This line creates a new `PCA` object with the `n_components` parameter set to `4`. This means that we want to extract 4 principal components from the standardized feature matrix.\n",
        "\n",
        "`principalComponents = pca.fit_transform(x)`: This line applies the `fit_transform()` method of the `PCA` object to the standardized feature matrix `x`. This method fits the PCA model to the data and transforms the data into the principal component space. The resulting `principalComponents` variable contains the transformed data.\n",
        "\n",
        "`principalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2', 'PC3', 'PC4'])`: This line creates a new DataFrame named `principalDataframe` with the transformed principal components. The data argument is set to `principalComponents`, and the columns argument specifies the names of the principal components, which are `PC1`, `PC2`, `PC3`, and `PC4`.\n",
        "\n",
        "`print(principalDataframe)`: This line prints the `principalDataframe` DataFrame to the console, which contains the principal components of the iris dataset.\n",
        "\n",
        "Overall, this code performs PCA on the standardized features of the iris dataset, which reduces the dimensionality of the data while preserving the most important information. The resulting principal components can be used for visualization or as input features for machine learning models.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CFGJIf55iYAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,  # transpose the matrix of loadings\n",
        "    columns= ['PC1', 'PC2', 'PC3', 'PC4'],  # so the columns are the principal components\n",
        "    index=features,  # and the rows are the original features\n",
        ")\n",
        "loadings"
      ],
      "metadata": {
        "id": "IGMkYfkMvtr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet creates a new DataFrame named loadings that contains the loadings matrix for the principal components obtained from the PCA analysis. Here is an explanation of each line of code:\n",
        "\n",
        "`loadings = pd.DataFrame(pca.components_.T, columns= ['PC1', 'PC2', 'PC3', 'PC4'], index=features)`: This line creates a new DataFrame named `loadings` that contains the loadings matrix for the principal components obtained from the PCA analysis. The `pca.components_.T` attribute is used to obtain the transpose of the loadings matrix, which is arranged with one row for each principal component and one column for each original feature. The columns argument specifies the names of the principal components, which are `PC1`, `PC2`, `PC3`, and `PC4`, and the `index` argument specifies the names of the original features, which are `sepal length`, `sepal width`, `petal length`, and `petal width`.\n",
        "\n",
        "`loadings`: This line simply prints the `loadings` DataFrame to the console.\n",
        "\n",
        "Overall, this code creates a DataFrame that shows how each original feature contributes to each principal component. The loadings matrix is a key output of a PCA analysis, as it helps to interpret the principal components in terms of the original features. The loadings can be used to identify which original features are most strongly associated with each principal component, and to understand the underlying structure of the data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WvEZ04QYjfCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Combine the Target and the Principal Components"
      ],
      "metadata": {
        "id": "TYE2MyteDAmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetDataframe = df[['target']]\n",
        "newDataframe = pd.concat([principalDataframe, targetDataframe],axis = 1)\n",
        "print(newDataframe)"
      ],
      "metadata": {
        "id": "fJ-OEC8CDL2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Perform a Scree Plot of the Principal Components"
      ],
      "metadata": {
        "id": "LMkoXzyyDMXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "percent_variance = np.round(pca.explained_variance_ratio_* 100, decimals =2)\n",
        "columns = ['PC1', 'PC2', 'PC3', 'PC4']\n",
        "print(percent_variance)\n",
        "plt.bar(x= range(1,5), height=percent_variance, tick_label=columns)\n",
        "plt.ylabel('Percentate of Variance Explained')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.title('PCA Scree Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lEJJRvj7DUsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet generates a scree plot to show the percentage of variance explained by each principal component obtained from the PCA analysis. Here is an explanation of each line of code:\n",
        "\n",
        "`percent_variance = np.round(pca.explained_variance_ratio_* 100, decimals =2)`: This line calculates the percentage of variance explained by each principal component and rounds the values to 2 decimal places. The `pca.explained_variance_ratio_` attribute is used to obtain the proportion of the total variance explained by each principal component.\n",
        "\n",
        "`columns = ['PC1', 'PC2', 'PC3', 'PC4']`: This line creates a list named columns that contains the names of the four principal components.\n",
        "\n",
        "p`rint(percent_variance)`: This line prints the `percent_variance` array to the console.\n",
        "\n",
        "p`lt.bar(x= range(1,5), height=percent_variance, tick_label=columns)`: This line creates a bar chart using `Matplotlib` to plot the percentage of variance explained by each principal component. The `x` parameter is set to `range(1,5)` to specify the x-axis values, which correspond to the four principal components. The height parameter is set to `percent_variance` to specify the y-axis values. The `tick_label` parameter is set to columns to label the x-axis ticks with the names of the principal components.\n",
        "\n",
        "`plt.ylabel('Percentate of Variance Explained')`: This line sets the y-axis label to `'Percentate of Variance Explained'`.\n",
        "\n",
        "`plt.xlabel('Principal Component')`: This line sets the x-axis label to `'Principal Component'`.\n",
        "\n",
        "`plt.title('PCA Scree Plot')`: This line sets the title of the plot to '`PCA Scree Plot'`.\n",
        "\n",
        "`plt.show()`: This line displays the plot.\n",
        "\n",
        "Overall, this code provides a visual representation of the proportion of variance explained by each principal component. The scree plot can be used to determine the optimal number of principal components to retain, as it shows the point at which the additional variance explained by each additional component becomes less important. In this case, the first two principal components explain a high percentage of the total variance, suggesting that they may be sufficient to represent the data."
      ],
      "metadata": {
        "id": "G_-HcIxOlHZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Plot the Principal Components on 2D"
      ],
      "metadata": {
        "id": "1zEr6D5jDVSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(principalDataframe.PC1, principalDataframe.PC2)\n",
        "plt.title('PC1 against PC2')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')"
      ],
      "metadata": {
        "id": "LiZLqK2wDexI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet generates a scatter plot to visualize the relationship between the first two principal components obtained from the PCA analysis. Here is an explanation of each line of code:\n",
        "\n",
        "`plt.scatter(principalDataframe.PC1, principalDataframe.PC2)`: This line creates a scatter plot using `Matplotlib` to plot the values of `PC1` on the x-axis and `PC2` on the y-axis. The `principalDataframe.PC1` and `principalDataframe.PC2` attributes are used to obtain the values of the first two principal components.\n",
        "\n",
        "`plt.title('PC1 against PC2')`: This line sets the title of the plot to `'PC1 against PC2'.`\n",
        "\n",
        "`plt.xlabel('PC1')`: This line sets the x-axis label to `'PC1'`.\n",
        "\n",
        "`plt.ylabel('PC2')`: This line sets the y-axis label to `'PC2'`.\n",
        "\n",
        "Overall, this code provides a visual representation of the relationship between the first two principal components. The scatter plot can be used to identify any patterns or clusters in the data, which may help to inform further analysis or modeling. In this case, the scatter plot may help to identify any groupings or separations between the different species of iris in the dataset."
      ],
      "metadata": {
        "id": "yg-QDDOTmGl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "\n",
        "ax.set_title('Plot of PC1 vs PC2', fontsize = 20)\n",
        "\n",
        "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
        "\n",
        "colors = ['r', 'g', 'b']\n",
        "\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = newDataframe['target'] == target\n",
        "    ax.scatter(newDataframe.loc[indicesToKeep, 'PC1']\n",
        "               , newDataframe.loc[indicesToKeep, 'PC2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "3KhSs5jbLHW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet generates a scatter plot to visualize the relationship between the first two principal components obtained from the PCA analysis, with different colors representing different species of iris. Here is an explanation of each line of code:\n",
        "\n",
        "`fig = plt.figure(figsize = (8,8))`: This line creates a new figure with a size of 8 by 8 inches.\n",
        "\n",
        "`ax = fig.add_subplot(1,1,1)`: This line creates a new subplot on the figure, with a grid of 1 row by 1 column and the first subplot.\n",
        "\n",
        "`ax.set_xlabel('PC1')`: This line sets the x-axis label to `'PC1'`.\n",
        "\n",
        "`ax.set_ylabel('PC2')`: This line sets the y-axis label to `'PC2'`.\n",
        "\n",
        "`ax.set_title('Plot of PC1 vs PC2', fontsize = 20)`: This line sets the title of the plot to `'Plot of PC1 vs PC2'` with a font size of `20`.\n",
        "\n",
        "`targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']`: This line creates a list of target species in the dataset.\n",
        "\n",
        "`colors = ['r', 'g', 'b']`: This line creates a list of colors to represent each species.\n",
        "\n",
        "`for target, color in zip(targets,colors):`: This line iterates through the list of targets and colors simultaneously.\n",
        "\n",
        "`indicesToKeep = newDataframe['target'] == target`: This line creates a Boolean array `indicesToKeep` that is `True` for rows where the target species matches the current target.\n",
        "\n",
        "`ax.scatter(newDataframe.loc[indicesToKeep, 'PC1'], newDataframe.loc[indicesToKeep, 'PC2'], c = color, s = 50)`: This line plots a scatter plot of the principal components `PC1` and `PC2` for the rows where the target species matches the current target. The `c` parameter sets the color of the points to the current color, and the `s` parameter sets the size of the points to `50`.\n",
        "\n",
        "`ax.legend(targets)`: This line adds a legend to the plot, with the target species names as labels.\n",
        "\n",
        "`ax.grid()`: This line adds a grid to the plot.\n",
        "\n",
        "Overall, this code provides a visual representation of the relationship between the first two principal components, with different colors representing different species of iris. The scatter plot can be used to identify any patterns or clusters in the data, which may help to inform further analysis or modeling. In this case, the scatter plot may help to identify any groupings or separations between the different species of iris in the dataset."
      ],
      "metadata": {
        "id": "ic9tsQKDm2_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Visualizing Further the Explained Variance Using Principal Component"
      ],
      "metadata": {
        "id": "957msJfDDfai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "VVai4DgTDsHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_variance(pca, width=8, dpi=100):\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "    # Explained variance\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Cumulative Variance\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Set up figure\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "\n",
        "# Look at explained variance\n",
        "plot_variance(pca);"
      ],
      "metadata": {
        "id": "wgd7VwPE0iGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Task\n",
        "Apply Steps 1 to Step 8 (part one) to the\n",
        "[Automobile dataset](https://www.kaggle.com/datasets/toramky/automobile-dataset).\n",
        "\n",
        "Use only the following features in your ACP analysis:\n",
        "\n",
        "`features = [\"highway_mpg\", \"engine_size\", \"horsepower\", \"curb_weight\"]`\n",
        "\n",
        "Try to interpret the results.\n"
      ],
      "metadata": {
        "id": "YtLIcFfB_esT"
      }
    }
  ]
}